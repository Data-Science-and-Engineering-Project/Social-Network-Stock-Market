{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d870142",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e54b6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "# Graph libraries\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "from networkx.algorithms.centrality import degree_centrality, closeness_centrality\n",
    "from networkx.algorithms.link_analysis.pagerank_alg import pagerank\n",
    "from networkx.algorithms.link_analysis.hits_alg import hits\n",
    "import igraph as ig\n",
    "import leidenalg as la\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.metrics import roc_auc_score, precision_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Deep learning libraries\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11d2a810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded environment from: C:\\Users\\potda\\Daniel\\BGU\\Year_D\\Final_Project\\Social-Network-Stock-Market\\.env\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# Try to load .env from multiple locations\n",
    "env_paths = [\n",
    "    Path(r'C:\\Users\\potda\\Daniel\\BGU\\Year_D\\Final_Project\\Social-Network-Stock-Market\\.env'),\n",
    "    Path.cwd() / '.env',  # Current directory\n",
    "    Path.cwd().parent / '.env',  # Parent directory (project root)\n",
    "]\n",
    "\n",
    "for env_path in env_paths:\n",
    "    if env_path.exists():\n",
    "        load_dotenv(env_path)\n",
    "        print(f\"Loaded environment from: {env_path}\")\n",
    "        break\n",
    "else:\n",
    "    print(\"No .env file found in any of the checked locations\")\n",
    "\n",
    "# Now you can use os.getenv() to access your variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b219e3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Database configuration:\n",
      "  DB_HOST: 127.0.0.1\n",
      "  DB_PORT: 5432\n",
      "  DB_NAME: Social_13F\n",
      "  DB_USER: postgres\n",
      "  DB_PASSWORD: *******\n"
     ]
    }
   ],
   "source": [
    "# Verify database environment variables are loaded\n",
    "print(\"\\nDatabase configuration:\")\n",
    "print(f\"  DB_HOST: {os.getenv('DB_HOST', 'Not set')}\")\n",
    "print(f\"  DB_PORT: {os.getenv('DB_PORT', 'Not set')}\")\n",
    "print(f\"  DB_NAME: {os.getenv('DB_NAME', 'Not set')}\")\n",
    "print(f\"  DB_USER: {os.getenv('DB_USER', 'Not set')}\")\n",
    "print(f\"  DB_PASSWORD: {'*' * len(os.getenv('DB_PASSWORD', '')) if os.getenv('DB_PASSWORD') else 'Not set'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37aafe3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: c:\\Users\\potda\\Daniel\\BGU\\Year_D\\Final_Project\\Social-Network-Stock-Market\n",
      "Python path includes: True\n"
     ]
    }
   ],
   "source": [
    "# Calculate project root path\n",
    "# If notebook is in Notebooks/LightGCN/, go up 2 levels to project root\n",
    "notebook_path = Path.cwd()  # Current working directory\n",
    "project_root = notebook_path.parent.parent  # Go up 2 levels\n",
    "\n",
    "# Add project root to Python path\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Python path includes: {str(project_root) in sys.path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb3d3c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ETL.data_handlers.db_data_handler.postgres_handler import PostgresHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d9edf13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.6.0+cu124\n",
      "CUDA Available: True\n",
      "CUDA Version: 12.4\n",
      "Number of GPUs: 1\n",
      "GPU 0: NVIDIA GeForce RTX 3050 6GB Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# GPU Diagnostics\n",
    "# ============================================================================\n",
    "\n",
    "def check_gpu_support():\n",
    "    \"\"\"Check PyTorch CUDA support and GPU availability.\"\"\"\n",
    "    print(\"PyTorch Version:\", torch.__version__)\n",
    "    print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "        print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    else:\n",
    "        print(\"\\n⚠ CUDA not available!\")\n",
    "        print(\"Possible reasons:\")\n",
    "        print(\"1. PyTorch installed without CUDA support (CPU-only version)\")\n",
    "        print(\"2. CUDA drivers not installed\")\n",
    "        print(\"3. PyTorch version incompatible with CUDA version\")\n",
    "        print(\"\\nTo install PyTorch with CUDA support:\")\n",
    "        print(\"Visit: https://pytorch.org/get-started/locally/\")\n",
    "        print(\"Or run: pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\")\n",
    "\n",
    "check_gpu_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9684f850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Using GPU: NVIDIA GeForce RTX 3050 6GB Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Device Configuration\n",
    "def get_device():\n",
    "    \"\"\"Get available device (CUDA if available, else CPU).\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        print(f\"✓ Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        print(f\"✓ Using CPU\")\n",
    "    return device\n",
    "\n",
    "# Set device\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fedd50",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73550e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-14 23:57:45 - ETL_Pipeline - INFO - Connected to PostgreSQL: postgres@127.0.0.1:5432/Social_13F\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Connecting to database...\n",
      "✓ Connected to database: Social_13F\n",
      "\n",
      "Loading data from holdings_filtered_new where period_start = '2024-01-01'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-14 23:57:51 - ETL_Pipeline - INFO - Disconnected from PostgreSQL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded 1,723,925 rows\n",
      "\n",
      "DataFrame shape: (1723925, 6)\n",
      "\n",
      "First 5 rows:\n",
      "         nameofissuer      cusip  sshprnamt         cik period_start     price\n",
      "0     ABBOTT LABS COM  002824100     1863.0  0001800597   2024-01-01  108.3693\n",
      "1          ABBVIE INC  00287Y109     5839.0  0001800597   2024-01-01  170.0935\n",
      "2           AFLAC INC  001055102     5450.0  0001800597   2024-01-01   82.1170\n",
      "3  ALLIANT CORP STOCK  018802108     4506.0  0001800597   2024-01-01   46.8504\n",
      "4      AMAZON COM INC  023135106     1488.0  0001800597   2024-01-01  180.9700\n",
      "\n",
      "✓ Database connection closed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Import database handler (it will use the environment variables we just loaded)\n",
    "# Connect to database using environment variables\n",
    "print(\"\\nConnecting to database...\")\n",
    "handler = PostgresHandler()\n",
    "\n",
    "if not handler.connect():\n",
    "    raise ConnectionError(\"Failed to connect to database\")\n",
    "\n",
    "print(f\"✓ Connected to database: {handler.database}\")\n",
    "\n",
    "# Query to load holdings_filtered_new where period_start = '2024-01-01'\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    hf.nameofissuer,\n",
    "    hf.cusip,\n",
    "    hf.sshprnamt,\n",
    "    hf.cik,\n",
    "    hf.period_start,\n",
    "    tp.price\n",
    "FROM holdings_filtered_new hf\n",
    "INNER JOIN ticker_to_cusip ttc ON hf.cusip = ttc.cusip\n",
    "INNER JOIN ticker_prices tp ON ttc.ticker = tp.ticker \n",
    "    AND hf.period_start = CAST(tp.period_start AS DATE)\n",
    "WHERE hf.period_start = '2024-01-01'\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nLoading data from holdings_filtered_new where period_start = '2024-01-01'...\")\n",
    "df = pd.read_sql_query(query, handler.connection)\n",
    "print(f\"✓ Loaded {len(df):,} rows\")\n",
    "print(f\"\\nDataFrame shape: {df.shape}\")\n",
    "\n",
    "# Display first few rows\n",
    "if len(df) > 0:\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"\\n⚠ No data found for period_start = '2024-01-01'\")\n",
    "\n",
    "# Close connection\n",
    "handler.disconnect()\n",
    "print(\"\\n✓ Database connection closed\")\n",
    "\n",
    "# Now you can use the DataFrame 'df' for your analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d30475e",
   "metadata": {},
   "source": [
    "## Describe the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5fb17a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filtering: 1,723,925 rows\n",
      "  - sshprnamt = 0: 3,730\n",
      "  - price = 0: 0\n",
      "\n",
      "After filtering: 1,720,195 rows\n",
      "✓ Removed 0 rows with zero values\n"
     ]
    }
   ],
   "source": [
    "# Filter Zero Values\n",
    "\n",
    "print(f\"Before filtering: {len(df):,} rows\")\n",
    "print(f\"  - sshprnamt = 0: {(df['sshprnamt'] == 0).sum():,}\")\n",
    "print(f\"  - price = 0: {(df['price'] == 0).sum():,}\")\n",
    "\n",
    "# Filter out zeros\n",
    "df = df[(df['sshprnamt'] != 0) & (df['price'] != 0)].copy()\n",
    "\n",
    "print(f\"\\nAfter filtering: {len(df):,} rows\")\n",
    "print(f\"✓ Removed {(df['sshprnamt'] == 0).sum() + (df['price'] == 0).sum():,} rows with zero values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d22fc7be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sshprnamt</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.720195e+06</td>\n",
       "      <td>1.720195e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.483841e+05</td>\n",
       "      <td>1.379459e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.059934e+06</td>\n",
       "      <td>2.731320e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.000000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.061000e+03</td>\n",
       "      <td>3.217230e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.390000e+03</td>\n",
       "      <td>7.612000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.058250e+04</td>\n",
       "      <td>1.667420e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.255168e+09</td>\n",
       "      <td>8.026270e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sshprnamt         price\n",
       "count  1.720195e+06  1.720195e+06\n",
       "mean   2.483841e+05  1.379459e+02\n",
       "std    3.059934e+06  2.731320e+02\n",
       "min    1.000000e+00  7.000000e-04\n",
       "25%    1.061000e+03  3.217230e+01\n",
       "50%    8.390000e+03  7.612000e+01\n",
       "75%    5.058250e+04  1.667420e+02\n",
       "max    1.255168e+09  8.026270e+03"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "69eabb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 205,662 duplicate pairs (842,948 total rows)\n",
      "\n",
      "First 10 duplicate pairs:\n",
      "\n",
      "Pair 1: CIK=0000003520, CUSIP=000361105\n",
      "  Occurrences: 2\n",
      "  Weights: [1322599.5, 29461544.4]\n",
      "  Names: ['AAR CORP']\n",
      "\n",
      "Pair 2: CIK=0000003520, CUSIP=004225108\n",
      "  Occurrences: 2\n",
      "  Weights: [1931615.84, 39291502.800000004]\n",
      "  Names: ['ACADIA PHARMACEUTICALS INC']\n",
      "\n",
      "Pair 3: CIK=0000003520, CUSIP=00847J105\n",
      "  Occurrences: 2\n",
      "  Weights: [13686389.85, 64389186.15]\n",
      "  Names: ['AGILYSYS INC']\n",
      "\n",
      "Pair 4: CIK=0000003520, CUSIP=125141101\n",
      "  Occurrences: 2\n",
      "  Weights: [7964555.0, 350865.0]\n",
      "  Names: ['CECO ENVIRONMENTAL CORP']\n",
      "\n",
      "Pair 5: CIK=0000003520, CUSIP=12763L105\n",
      "  Occurrences: 2\n",
      "  Weights: [491546.1992, 11166380.899799999]\n",
      "  Names: ['CADRE HOLDINGS INC']\n",
      "\n",
      "Pair 6: CIK=0000003520, CUSIP=147448104\n",
      "  Occurrences: 2\n",
      "  Weights: [113906202.0, 5288649.5]\n",
      "  Names: ['CASELLA WASTE SYSTEMS']\n",
      "\n",
      "Pair 7: CIK=0000003520, CUSIP=21867A105\n",
      "  Occurrences: 2\n",
      "  Weights: [585701.85, 14116898.021999998]\n",
      "  Names: ['CORE LABORATORIES INC']\n",
      "\n",
      "Pair 8: CIK=0000003520, CUSIP=24477E103\n",
      "  Occurrences: 2\n",
      "  Weights: [16820304.0, 906456.0]\n",
      "  Names: ['DEFINITIVE HEALTHCARE CORP']\n",
      "\n",
      "Pair 9: CIK=0000003520, CUSIP=262037104\n",
      "  Occurrences: 2\n",
      "  Weights: [8650537.92, 490737.24]\n",
      "  Names: ['DRIL-QUIP INC']\n",
      "\n",
      "Pair 10: CIK=0000003520, CUSIP=302492103\n",
      "  Occurrences: 2\n",
      "  Weights: [1098456.24, 27870236.16]\n",
      "  Names: ['FLYWIRE CORPORATION']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Quick View of Duplicate Pairs\n",
    "\n",
    "def quick_view_duplicates(df):\n",
    "    \"\"\"\n",
    "    Quick view of duplicate pairs with summary.\n",
    "    \"\"\"\n",
    "    # Find duplicates\n",
    "    duplicates = df[df.duplicated(subset=['cik', 'cusip'], keep=False)]\n",
    "    \n",
    "    if len(duplicates) == 0:\n",
    "        print(\"✓ No duplicate pairs found!\")\n",
    "        return\n",
    "    \n",
    "    # Group by (cik, cusip) and show details\n",
    "    duplicate_groups = duplicates.groupby(['cik', 'cusip'])\n",
    "    \n",
    "    print(f\"Found {len(duplicate_groups):,} duplicate pairs ({len(duplicates):,} total rows)\")\n",
    "    print(\"\\nFirst 10 duplicate pairs:\\n\")\n",
    "    \n",
    "    for idx, ((cik, cusip), group) in enumerate(duplicate_groups, 1):\n",
    "        if idx > 10:\n",
    "            break\n",
    "        \n",
    "        print(f\"Pair {idx}: CIK={cik}, CUSIP={cusip}\")\n",
    "        print(f\"  Occurrences: {len(group)}\")\n",
    "        print(f\"  Weights: {group['weight'].tolist()}\")\n",
    "        print(f\"  Names: {group['nameofissuer'].unique().tolist()}\")\n",
    "        print()\n",
    "    \n",
    "    # Return the duplicates DataFrame for further inspection\n",
    "    return duplicates.sort_values(['cik', 'cusip'])\n",
    "\n",
    "# Quick view\n",
    "duplicate_df = quick_view_duplicates(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d4563f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Merging Duplicate Rows (Detailed)\n",
      "================================================================================\n",
      "Original rows: 1,720,195\n",
      "\n",
      "Found 205,662 duplicate pairs\n",
      "  - Pairs with identical sshprnamt: 17,313\n",
      "  - Pairs with different sshprnamt: 188,349\n",
      "  - Rows to be removed (identical): 17,931\n",
      "  - Rows to be summed (different): 619,355\n",
      "\n",
      "Merging...\n",
      "\n",
      "================================================================================\n",
      "Merge Complete\n",
      "================================================================================\n",
      "Original rows: 1,720,195\n",
      "Merged rows: 1,082,909\n",
      "Reduction: 637,286 rows (37.05%)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Merge Duplicate Rows (With Details)\n",
    "\n",
    "def merge_duplicate_rows_detailed(df):\n",
    "    \"\"\"\n",
    "    Merge rows with detailed reporting of what was merged.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Merging Duplicate Rows (Detailed)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    original_count = len(df)\n",
    "    print(f\"Original rows: {original_count:,}\\n\")\n",
    "    \n",
    "    # Find duplicates before merging\n",
    "    duplicates = df[df.duplicated(subset=['cik', 'cusip'], keep=False)]\n",
    "    duplicate_groups = duplicates.groupby(['cik', 'cusip'])\n",
    "    \n",
    "    print(f\"Found {len(duplicate_groups):,} duplicate pairs\")\n",
    "    \n",
    "    # Count how many will be summed vs removed\n",
    "    summed_count = 0\n",
    "    removed_count = 0\n",
    "    \n",
    "    for (cik, cusip), group in duplicate_groups:\n",
    "        if group['sshprnamt'].nunique() == 1:\n",
    "            removed_count += len(group) - 1  # Keep 1, remove rest\n",
    "        else:\n",
    "            summed_count += len(group) - 1   # Sum into 1\n",
    "    \n",
    "    print(f\"  - Pairs with identical sshprnamt: {sum(1 for _, g in duplicate_groups if g['sshprnamt'].nunique() == 1):,}\")\n",
    "    print(f\"  - Pairs with different sshprnamt: {sum(1 for _, g in duplicate_groups if g['sshprnamt'].nunique() > 1):,}\")\n",
    "    print(f\"  - Rows to be removed (identical): {removed_count:,}\")\n",
    "    print(f\"  - Rows to be summed (different): {summed_count:,}\")\n",
    "    \n",
    "    # Perform merge\n",
    "    print(\"\\nMerging...\")\n",
    "    agg_dict = {\n",
    "        'sshprnamt': 'sum',\n",
    "        'price': 'first',\n",
    "        'nameofissuer': 'first',\n",
    "        'period_start': 'first'\n",
    "    }\n",
    "    \n",
    "    df_merged = df.groupby(['cik', 'cusip'], as_index=False).agg(agg_dict)\n",
    "    df_merged['weight'] = df_merged['sshprnamt'] * df_merged['price']\n",
    "    \n",
    "    final_count = len(df_merged)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Merge Complete\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Original rows: {original_count:,}\")\n",
    "    print(f\"Merged rows: {final_count:,}\")\n",
    "    print(f\"Reduction: {original_count - final_count:,} rows ({100*(original_count-final_count)/original_count:.2f}%)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    return df_merged\n",
    "\n",
    "# Merge with details\n",
    "df = merge_duplicate_rows_detailed(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "50752017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1082909, 7)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f593c3",
   "metadata": {},
   "source": [
    "## Building The graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a4638e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f494cde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building bipartite graph (optimized)...\n",
      "============================================================\n",
      "Building Bipartite Graph (Optimized)\n",
      "============================================================\n",
      "\n",
      "[1/4] Calculating edge weights...\n",
      "     ✓ Completed in 0.01s\n",
      "\n",
      "[2/4] Creating graph and adding nodes...\n",
      "     ✓ Added 7,058 funds and 2,911 stocks in 0.08s\n",
      "\n",
      "[3/4] Creating edge list (vectorized)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     Processing edges: 100%|██████████| 1.08M/1.08M [00:00<00:00, 5.48Medges/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ✓ Created 1,082,909 edges in 0.20s\n",
      "\n",
      "[4/4] Adding edges to graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     Adding to graph: 100%|██████████| 1/1 [00:01<00:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ✓ Added edges in 1.70s\n",
      "\n",
      "============================================================\n",
      "Construction Complete\n",
      "============================================================\n",
      "Total time: 1.99s (0.03 min)\n",
      "Speed: 545,378 edges/second\n",
      "Nodes: 9,969\n",
      "Edges: 1,082,909\n",
      "============================================================\n",
      "\n",
      "✓ Graph created: 9,969 nodes, 1,082,909 edges\n",
      "  - Funds (CIK): 7,058\n",
      "  - Stocks (CUSIP): 2,911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Step 1: Build Bipartite Graph (Fastest with Progress Bar)\n",
    "# ============================================================================\n",
    "\n",
    "def calculate_edge_weights(df):\n",
    "    \"\"\"Calculate edge weights as sshprnamt * price.\"\"\"\n",
    "    df['weight'] = df['sshprnamt'] * df['price']\n",
    "    return df\n",
    "\n",
    "def build_bipartite_graph_fastest(df):\n",
    "    \"\"\"\n",
    "    Fastest method using pure vectorized operations with progress tracking.\n",
    "    Uses add_weighted_edges_from for optimal performance.\n",
    "    \"\"\"\n",
    "    import time\n",
    "    start = time.time()\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"Building Bipartite Graph (Optimized)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Step 1: Calculate weights\n",
    "    print(\"\\n[1/4] Calculating edge weights...\")\n",
    "    weight_start = time.time()\n",
    "    df = calculate_edge_weights(df)\n",
    "    print(f\"     ✓ Completed in {time.time() - weight_start:.2f}s\")\n",
    "    \n",
    "    # Step 2: Create graph and add nodes\n",
    "    print(\"\\n[2/4] Creating graph and adding nodes...\")\n",
    "    node_start = time.time()\n",
    "    \n",
    "    G = nx.Graph()\n",
    "    \n",
    "    funds = df['cik'].unique()\n",
    "    G.add_nodes_from(funds, bipartite=0)\n",
    "    \n",
    "    stocks = df['cusip'].unique()\n",
    "    G.add_nodes_from(stocks, bipartite=1)\n",
    "    \n",
    "    print(f\"     ✓ Added {len(funds):,} funds and {len(stocks):,} stocks in {time.time() - node_start:.2f}s\")\n",
    "    \n",
    "    # Step 3: Create edge list (vectorized - fastest)\n",
    "    print(\"\\n[3/4] Creating edge list (vectorized)...\")\n",
    "    edge_start = time.time()\n",
    "    \n",
    "    # Progress bar for edge creation\n",
    "    with tqdm(total=len(df), desc=\"     Processing edges\", unit=\"edges\", unit_scale=True) as pbar:\n",
    "        # Vectorized edge creation - fastest method\n",
    "        edges = list(zip(\n",
    "            df['cik'].values,\n",
    "            df['cusip'].values,\n",
    "            df['weight'].values\n",
    "        ))\n",
    "        pbar.update(len(df))\n",
    "    \n",
    "    print(f\"     ✓ Created {len(edges):,} edges in {time.time() - edge_start:.2f}s\")\n",
    "    \n",
    "    # Step 4: Add edges to graph\n",
    "    print(\"\\n[4/4] Adding edges to graph...\")\n",
    "    add_start = time.time()\n",
    "    \n",
    "    # Use add_weighted_edges_from - fastest method\n",
    "    with tqdm(total=1, desc=\"     Adding to graph\") as pbar:\n",
    "        G.add_weighted_edges_from(edges, weight='weight')\n",
    "        pbar.update(1)\n",
    "    \n",
    "    print(f\"     ✓ Added edges in {time.time() - add_start:.2f}s\")\n",
    "    \n",
    "    # Summary\n",
    "    elapsed = time.time() - start\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Construction Complete\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Total time: {elapsed:.2f}s ({elapsed/60:.2f} min)\")\n",
    "    print(f\"Speed: {len(df)/elapsed:,.0f} edges/second\")\n",
    "    print(f\"Nodes: {G.number_of_nodes():,}\")\n",
    "    print(f\"Edges: {G.number_of_edges():,}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return G, funds, stocks\n",
    "\n",
    "# Build the graph (replace Cell 11 with this)\n",
    "print(\"Building bipartite graph (optimized)...\")\n",
    "G_bipartite, funds, stocks = build_bipartite_graph_fastest(df)\n",
    "\n",
    "print(f\"\\n✓ Graph created: {G_bipartite.number_of_nodes():,} nodes, {G_bipartite.number_of_edges():,} edges\")\n",
    "print(f\"  - Funds (CIK): {len(funds):,}\")\n",
    "print(f\"  - Stocks (CUSIP): {len(stocks):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5b959f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Graph Validation Report\n",
      "================================================================================\n",
      "\n",
      "Test 1: PASS\n",
      "  CIK: 0000807249\n",
      "  CUSIP: 307675108\n",
      "  Edge exists: True\n",
      "  Weight match: True\n",
      "  Expected: 2805480.000000\n",
      "  Actual: 2805480.000000\n",
      "\n",
      "Test 2: PASS\n",
      "  CIK: 0001890698\n",
      "  CUSIP: 478160104\n",
      "  Edge exists: True\n",
      "  Weight match: True\n",
      "  Expected: 229371.196600\n",
      "  Actual: 229371.196600\n",
      "\n",
      "Test 3: PASS\n",
      "  CIK: 0001512404\n",
      "  CUSIP: 25809K105\n",
      "  Edge exists: True\n",
      "  Weight match: True\n",
      "  Expected: 402031.000000\n",
      "  Actual: 402031.000000\n",
      "\n",
      "Test 4: PASS\n",
      "  CIK: 0001801619\n",
      "  CUSIP: 74276R102\n",
      "  Edge exists: True\n",
      "  Weight match: True\n",
      "  Expected: 2015.060000\n",
      "  Actual: 2015.060000\n",
      "\n",
      "Test 5: PASS\n",
      "  CIK: 0000884548\n",
      "  CUSIP: 17275R102\n",
      "  Edge exists: True\n",
      "  Weight match: True\n",
      "  Expected: 417369.579200\n",
      "  Actual: 417369.579200\n",
      "\n",
      "Test 6: PASS\n",
      "  CIK: 0001801507\n",
      "  CUSIP: 46625H100\n",
      "  Edge exists: True\n",
      "  Weight match: True\n",
      "  Expected: 1541078.396000\n",
      "  Actual: 1541078.396000\n",
      "\n",
      "Test 7: PASS\n",
      "  CIK: 0001126328\n",
      "  CUSIP: 060505104\n",
      "  Edge exists: True\n",
      "  Weight match: True\n",
      "  Expected: 544837722.483600\n",
      "  Actual: 544837722.483600\n",
      "\n",
      "Test 8: PASS\n",
      "  CIK: 0002027836\n",
      "  CUSIP: 023135106\n",
      "  Edge exists: True\n",
      "  Weight match: True\n",
      "  Expected: 306382.210000\n",
      "  Actual: 306382.210000\n",
      "\n",
      "Test 9: PASS\n",
      "  CIK: 0000884546\n",
      "  CUSIP: 35086T109\n",
      "  Edge exists: True\n",
      "  Weight match: True\n",
      "  Expected: 30962771.453600\n",
      "  Actual: 30962771.453600\n",
      "\n",
      "Test 10: PASS\n",
      "  CIK: 0000201772\n",
      "  CUSIP: 500600101\n",
      "  Edge exists: True\n",
      "  Weight match: True\n",
      "  Expected: 2135977.720000\n",
      "  Actual: 2135977.720000\n",
      "\n",
      "================================================================================\n",
      "Summary: 10/10 tests passed (100.0%)\n",
      "✓ Graph construction validated successfully!\n"
     ]
    }
   ],
   "source": [
    "# Graph Validation: Detailed Test\n",
    "\n",
    "def detailed_validate_graph(df, G, num_samples=10):\n",
    "    \"\"\"\n",
    "    Detailed validation with edge-by-edge comparison.\n",
    "    \"\"\"\n",
    "    sample_df = df.sample(n=min(num_samples, len(df)), random_state=42)\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"Graph Validation Report\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    validation_data = []\n",
    "    \n",
    "    for idx, (_, row) in enumerate(sample_df.iterrows(), 1):\n",
    "        cik = row['cik']\n",
    "        cusip = row['cusip']\n",
    "        expected_weight = row['weight']\n",
    "        \n",
    "        exists = G.has_edge(cik, cusip)\n",
    "        actual_weight = G[cik][cusip]['weight'] if exists else None\n",
    "        weight_ok = abs(actual_weight - expected_weight) < 1e-6 if exists else False\n",
    "        \n",
    "        validation_data.append({\n",
    "            'test_num': idx,\n",
    "            'cik': cik,\n",
    "            'cusip': cusip,\n",
    "            'exists': exists,\n",
    "            'weight_ok': weight_ok,\n",
    "            'expected': expected_weight,\n",
    "            'actual': actual_weight\n",
    "        })\n",
    "        \n",
    "        status = \"PASS\" if (exists and weight_ok) else \"FAIL\"\n",
    "        print(f\"\\nTest {idx}: {status}\")\n",
    "        print(f\"  CIK: {cik}\")\n",
    "        print(f\"  CUSIP: {cusip}\")\n",
    "        print(f\"  Edge exists: {exists}\")\n",
    "        if exists:\n",
    "            print(f\"  Weight match: {weight_ok}\")\n",
    "            print(f\"  Expected: {expected_weight:.6f}\")\n",
    "            print(f\"  Actual: {actual_weight:.6f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    \n",
    "    # Summary\n",
    "    passed = sum(1 for v in validation_data if v['exists'] and v['weight_ok'])\n",
    "    total = len(validation_data)\n",
    "    \n",
    "    print(f\"Summary: {passed}/{total} tests passed ({100*passed/total:.1f}%)\")\n",
    "    \n",
    "    if passed == total:\n",
    "        print(\"✓ Graph construction validated successfully!\")\n",
    "    else:\n",
    "        print(\"⚠ Some validation tests failed\")\n",
    "    \n",
    "    return validation_data\n",
    "\n",
    "# Run detailed validation\n",
    "validation_data = detailed_validate_graph(df, G_bipartite, num_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "82b871e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting edges...\n",
      "============================================================\n",
      "Splitting Edges into Train/Val/Test\n",
      "============================================================\n",
      "\n",
      "[1/3] Shuffling data...\n",
      "\n",
      "[2/3] Splitting edges...\n",
      "\n",
      "[3/3] Verifying node coverage...\n",
      "  ⚠ Warning: Some nodes only in val/test sets\n",
      "    Moving 74 edges to train...\n",
      "\n",
      "============================================================\n",
      "Split Complete\n",
      "============================================================\n",
      "Total edges: 1,082,909\n",
      "Train: 866,406 (80.0%)\n",
      "Validation: 108,254 (10.0%)\n",
      "Test: 108,249 (10.0%)\n",
      "Time: 7.00s\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Step 1: Split Edges into Train/Val/Test (80/10/10)\n",
    "# ============================================================================\n",
    "\n",
    "def split_dataframe_edges(df, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1, random_seed=42):\n",
    "    \"\"\"\n",
    "    Split DataFrame edges into train, validation, and test sets.\n",
    "    Ensures all nodes appear in training set.\n",
    "    \"\"\"\n",
    "    import time\n",
    "    start = time.time()\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"Splitting Edges into Train/Val/Test\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Set random seed\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "    \n",
    "    # Shuffle DataFrame\n",
    "    print(\"\\n[1/3] Shuffling data...\")\n",
    "    df_shuffled = df.sample(frac=1, random_state=random_seed).reset_index(drop=True)\n",
    "    \n",
    "    # Calculate split sizes\n",
    "    total = len(df_shuffled)\n",
    "    train_size = int(total * train_ratio)\n",
    "    val_size = int(total * val_ratio)\n",
    "    \n",
    "    # Split\n",
    "    print(\"\\n[2/3] Splitting edges...\")\n",
    "    train_df = df_shuffled.iloc[:train_size].copy()\n",
    "    val_df = df_shuffled.iloc[train_size:train_size + val_size].copy()\n",
    "    test_df = df_shuffled.iloc[train_size + val_size:].copy()\n",
    "    \n",
    "    # Verify all nodes are in training set\n",
    "    print(\"\\n[3/3] Verifying node coverage...\")\n",
    "    train_funds = set(train_df['cik'].unique())\n",
    "    train_stocks = set(train_df['cusip'].unique())\n",
    "    \n",
    "    val_funds = set(val_df['cik'].unique())\n",
    "    val_stocks = set(val_df['cusip'].unique())\n",
    "    test_funds = set(test_df['cik'].unique())\n",
    "    test_stocks = set(test_df['cusip'].unique())\n",
    "    \n",
    "    # Check for nodes only in val/test\n",
    "    val_only_funds = val_funds - train_funds\n",
    "    val_only_stocks = val_stocks - train_stocks\n",
    "    test_only_funds = test_funds - train_funds\n",
    "    test_only_stocks = test_stocks - train_stocks\n",
    "    \n",
    "    if val_only_funds or val_only_stocks or test_only_funds or test_only_stocks:\n",
    "        print(f\"  ⚠ Warning: Some nodes only in val/test sets\")\n",
    "        print(f\"    Moving {len(val_only_funds) + len(val_only_stocks) + len(test_only_funds) + len(test_only_stocks)} edges to train...\")\n",
    "        \n",
    "        # Move edges with new nodes to train\n",
    "        val_new = val_df[val_df['cik'].isin(val_only_funds) | val_df['cusip'].isin(val_only_stocks)]\n",
    "        test_new = test_df[test_df['cik'].isin(test_only_funds) | test_df['cusip'].isin(test_only_stocks)]\n",
    "        \n",
    "        train_df = pd.concat([train_df, val_new, test_new], ignore_index=True)\n",
    "        val_df = val_df[~val_df.index.isin(val_new.index)]\n",
    "        test_df = test_df[~test_df.index.isin(test_new.index)]\n",
    "    \n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Split Complete\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Total edges: {total:,}\")\n",
    "    print(f\"Train: {len(train_df):,} ({100*len(train_df)/total:.1f}%)\")\n",
    "    print(f\"Validation: {len(val_df):,} ({100*len(val_df)/total:.1f}%)\")\n",
    "    print(f\"Test: {len(test_df):,} ({100*len(test_df)/total:.1f}%)\")\n",
    "    print(f\"Time: {elapsed:.2f}s\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "# Split the data\n",
    "print(\"Splitting edges...\")\n",
    "train_df, val_df, test_df = split_dataframe_edges(df, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ae619da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Building Graphs from Splits\n",
      "============================================================\n",
      "\n",
      "[1/2] Building training graph...\n",
      "============================================================\n",
      "Building Bipartite Graph (Optimized)\n",
      "============================================================\n",
      "\n",
      "[1/4] Calculating edge weights...\n",
      "     ✓ Completed in 0.01s\n",
      "\n",
      "[2/4] Creating graph and adding nodes...\n",
      "     ✓ Added 7,058 funds and 2,911 stocks in 0.15s\n",
      "\n",
      "[3/4] Creating edge list (vectorized)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     Processing edges: 100%|██████████| 866k/866k [00:00<00:00, 1.44Medges/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ✓ Created 866,406 edges in 0.61s\n",
      "\n",
      "[4/4] Adding edges to graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     Adding to graph: 100%|██████████| 1/1 [00:02<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ✓ Added edges in 2.31s\n",
      "\n",
      "============================================================\n",
      "Construction Complete\n",
      "============================================================\n",
      "Total time: 3.08s (0.05 min)\n",
      "Speed: 280,957 edges/second\n",
      "Nodes: 9,969\n",
      "Edges: 866,406\n",
      "============================================================\n",
      "\n",
      "[2/2] Building train+validation graph...\n",
      "============================================================\n",
      "Building Bipartite Graph (Optimized)\n",
      "============================================================\n",
      "\n",
      "[1/4] Calculating edge weights...\n",
      "     ✓ Completed in 0.02s\n",
      "\n",
      "[2/4] Creating graph and adding nodes...\n",
      "     ✓ Added 7,058 funds and 2,911 stocks in 0.17s\n",
      "\n",
      "[3/4] Creating edge list (vectorized)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     Processing edges: 100%|██████████| 975k/975k [00:00<00:00, 1.57Medges/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ✓ Created 974,660 edges in 0.63s\n",
      "\n",
      "[4/4] Adding edges to graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     Adding to graph: 100%|██████████| 1/1 [00:02<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ✓ Added edges in 2.37s\n",
      "\n",
      "============================================================\n",
      "Construction Complete\n",
      "============================================================\n",
      "Total time: 3.19s (0.05 min)\n",
      "Speed: 305,259 edges/second\n",
      "Nodes: 9,969\n",
      "Edges: 974,660\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Graphs Built\n",
      "============================================================\n",
      "Train graph: 9,969 nodes, 866,406 edges\n",
      "Train+Val graph: 9,969 nodes, 974,660 edges\n",
      "Time: 6.62s\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Build Separate Graphs (Train, Train+Val, Full)\n",
    "\n",
    "def build_graphs_from_splits(train_df, val_df):\n",
    "    \"\"\"\n",
    "    Build separate graphs for training and validation.\n",
    "    \"\"\"\n",
    "    import time\n",
    "    start = time.time()\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"Building Graphs from Splits\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Build train graph\n",
    "    print(\"\\n[1/2] Building training graph...\")\n",
    "    G_train, funds_train, stocks_train = build_bipartite_graph_fastest(train_df)\n",
    "    \n",
    "    # Build train+val graph (for validation)\n",
    "    print(\"\\n[2/2] Building train+validation graph...\")\n",
    "    train_val_df = pd.concat([train_df, val_df], ignore_index=True)\n",
    "    G_train_val, funds_train_val, stocks_train_val = build_bipartite_graph_fastest(train_val_df)\n",
    "    \n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Graphs Built\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Train graph: {G_train.number_of_nodes():,} nodes, {G_train.number_of_edges():,} edges\")\n",
    "    print(f\"Train+Val graph: {G_train_val.number_of_nodes():,} nodes, {G_train_val.number_of_edges():,} edges\")\n",
    "    print(f\"Time: {elapsed:.2f}s\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return G_train, G_train_val, funds_train, stocks_train\n",
    "\n",
    "# Build graphs\n",
    "G_train, G_train_val, funds_train, stocks_train = build_graphs_from_splits(train_df, val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "24503989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating node mappings...\n",
      "✓ Node mappings created\n",
      "  - Funds: 7,058\n",
      "  - Stocks: 2,911\n",
      "  - Total nodes: 9,969\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Create Node Mappings\n",
    "\n",
    "print(\"Creating node mappings...\")\n",
    "node_to_idx, fund_to_idx, stock_to_idx = create_node_mappings(funds_train, stocks_train)\n",
    "\n",
    "print(f\"✓ Node mappings created\")\n",
    "print(f\"  - Funds: {len(fund_to_idx):,}\")\n",
    "print(f\"  - Stocks: {len(stock_to_idx):,}\")\n",
    "print(f\"  - Total nodes: {len(node_to_idx):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting train graph to PyG format...\n",
      "============================================================\n",
      "Converting Graph to PyTorch Geometric Format\n",
      "============================================================\n",
      "\n",
      "[1/4] Extracting edges from graph...\n",
      "     ✓ Extracted 866,406 edges in 0.66s\n",
      "\n",
      "[2/4] Processing edge data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     Processing: 100%|██████████| 866k/866k [00:00<00:00, 1.19Medges/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ✓ Processed in 0.73s\n",
      "\n",
      "[3/4] Mapping nodes to indices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     Mapping: 100%|██████████| 866k/866k [00:00<00:00, 2.53Medges/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ✓ Mapped in 0.35s\n",
      "\n",
      "[4/4] Creating bidirectional edges and moving to device...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     Creating tensors: 100%|██████████| 1/1 [00:00<00:00, 19.84it/s]\n",
      "     Moving to device: 100%|██████████| 2/2 [00:00<00:00, 29.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     ✓ Completed in 0.13s\n",
      "\n",
      "============================================================\n",
      "Conversion Complete\n",
      "============================================================\n",
      "Total time: 1.86s\n",
      "Speed: 465,105 edges/second\n",
      "Edge index shape: torch.Size([2, 1732812]) (on cuda)\n",
      "Edge weights shape: torch.Size([1732812]) (on cuda)\n",
      "Total bidirectional edges: 1,732,812\n",
      "============================================================\n",
      "\n",
      "Converting train+val graph to PyG format...\n",
      "============================================================\n",
      "Converting Graph to PyTorch Geometric Format\n",
      "============================================================\n",
      "\n",
      "[1/4] Extracting edges from graph...\n",
      "     ✓ Extracted 974,660 edges in 3.15s\n",
      "\n",
      "[2/4] Processing edge data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     Processing: 100%|██████████| 975k/975k [00:00<00:00, 1.19Medges/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ✓ Processed in 0.82s\n",
      "\n",
      "[3/4] Mapping nodes to indices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     Mapping: 100%|██████████| 975k/975k [00:00<00:00, 2.99Medges/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ✓ Mapped in 0.33s\n",
      "\n",
      "[4/4] Creating bidirectional edges and moving to device...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     Creating tensors: 100%|██████████| 1/1 [00:00<00:00, 77.01it/s]\n",
      "     Moving to device: 100%|██████████| 2/2 [00:00<00:00, 54.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     ✓ Completed in 0.06s\n",
      "\n",
      "============================================================\n",
      "Conversion Complete\n",
      "============================================================\n",
      "Total time: 4.35s\n",
      "Speed: 223,825 edges/second\n",
      "Edge index shape: torch.Size([2, 1949320]) (on cuda)\n",
      "Edge weights shape: torch.Size([1949320]) (on cuda)\n",
      "Total bidirectional edges: 1,949,320\n",
      "============================================================\n",
      "\n",
      "✓ Edge indices created\n",
      "  - Train edges: 1,732,812\n",
      "  - Train+Val edges: 1,949,320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Convert Graphs to PyTorch Geometric Format\n",
    "\n",
    "# Convert train graph\n",
    "print(\"Converting train graph to PyG format...\")\n",
    "train_edge_index, train_edge_weights = graph_to_edge_index_fastest(G_train, node_to_idx, device)\n",
    "\n",
    "# Convert train+val graph (for validation)\n",
    "print(\"\\nConverting train+val graph to PyG format...\")\n",
    "train_val_edge_index, train_val_edge_weights = graph_to_edge_index_fastest(G_train_val, node_to_idx, device)\n",
    "\n",
    "print(f\"\\n✓ Edge indices created\")\n",
    "print(f\"  - Train edges: {train_edge_index.shape[1]:,}\")\n",
    "print(f\"  - Train+Val edges: {train_val_edge_index.shape[1]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6aadc291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training pairs...\n",
      "============================================================\n",
      "Creating Training Pairs\n",
      "============================================================\n",
      "\n",
      "[1/3] Extracting positive edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     Extracting: 100%|██████████| 1/1 [00:00<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ✓ Extracted 1,732,812 positive edges in 0.26s\n",
      "\n",
      "[2/3] Creating positive edge set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     Building set: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ✓ Created set in 2.17s\n",
      "\n",
      "[3/3] Sampling 1x negative edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     Sampling negatives: 1.75Medges [00:03, 530kedges/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ✓ Sampled 1,732,812 negative edges in 3.31s\n",
      "\n",
      "[4/4] Creating tensors and moving to device...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     Creating tensors: 100%|██████████| 2/2 [00:00<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ✓ Completed in 0.50s\n",
      "\n",
      "============================================================\n",
      "Training Pairs Created\n",
      "============================================================\n",
      "Total time: 6.24s\n",
      "Positive edges: 1,732,812\n",
      "Negative edges: 1,732,812\n",
      "Ratio: 1.00x\n",
      "Device: cuda\n",
      "============================================================\n",
      "\n",
      "Creating validation pairs...\n",
      "Sampling 108,254 negative edges for validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building train+val edge set: 100%|██████████| 1949320/1949320 [09:52<00:00, 3291.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Training pairs: 1,732,812 pos, 1,732,812 neg\n",
      "✓ Validation pairs: 108,254 pos, 108,254 neg\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Create Training and Validation Pairs (FIXED)\n",
    "\n",
    "# Training pairs (from train graph only)\n",
    "print(\"Creating training pairs...\")\n",
    "train_pos_edges, train_neg_edges = create_positive_negative_pairs_fastest(\n",
    "    train_edge_index, num_nodes, device, num_negatives=1\n",
    ")\n",
    "\n",
    "# Validation pairs (from train+val graph, but only validate on val edges)\n",
    "print(\"\\nCreating validation pairs...\")\n",
    "# Get validation edges only\n",
    "val_edge_pairs = []\n",
    "for _, row in val_df.iterrows():\n",
    "    if row['cik'] in fund_to_idx and row['cusip'] in stock_to_idx:\n",
    "        val_edge_pairs.append([fund_to_idx[row['cik']], stock_to_idx[row['cusip']]])\n",
    "\n",
    "val_pos_edges = torch.tensor(val_edge_pairs, dtype=torch.long).to(device)\n",
    "\n",
    "# Sample negative edges for validation - FIXED to ensure exact count\n",
    "print(f\"Sampling {len(val_pos_edges):,} negative edges for validation...\")\n",
    "val_neg_edges = []\n",
    "val_pos_set = set((u.item(), v.item()) for u, v in val_pos_edges)\n",
    "\n",
    "# Get all possible edges from train+val graph to avoid sampling from them\n",
    "train_val_set = set()\n",
    "for i in tqdm(range(train_val_edge_index.shape[1]), desc=\"Building train+val edge set\"):\n",
    "    u = train_val_edge_index[0, i].item()\n",
    "    v = train_val_edge_index[1, i].item()\n",
    "    train_val_set.add((u, v))\n",
    "    train_val_set.add((v, u))  # Add both directions\n",
    "\n",
    "# Sample negative edges that are NOT in train+val graph\n",
    "max_attempts = len(val_pos_edges) * 100  # Limit attempts\n",
    "attempts = 0\n",
    "while len(val_neg_edges) < len(val_pos_edges) and attempts < max_attempts:\n",
    "    u = random.randint(0, num_nodes - 1)\n",
    "    v = random.randint(0, num_nodes - 1)\n",
    "    if u != v and (u, v) not in train_val_set:\n",
    "        val_neg_edges.append([u, v])\n",
    "    attempts += 1\n",
    "\n",
    "# If we didn't get enough, fill with random edges (even if they might be in train)\n",
    "if len(val_neg_edges) < len(val_pos_edges):\n",
    "    print(f\"  ⚠ Warning: Only sampled {len(val_neg_edges):,} negatives, filling rest...\")\n",
    "    while len(val_neg_edges) < len(val_pos_edges):\n",
    "        u = random.randint(0, num_nodes - 1)\n",
    "        v = random.randint(0, num_nodes - 1)\n",
    "        if u != v and (u, v) not in val_pos_set:\n",
    "            val_neg_edges.append([u, v])\n",
    "\n",
    "val_neg_edges = torch.tensor(val_neg_edges[:len(val_pos_edges)], dtype=torch.long).to(device)\n",
    "\n",
    "print(f\"\\n✓ Training pairs: {len(train_pos_edges):,} pos, {len(train_neg_edges):,} neg\")\n",
    "print(f\"✓ Validation pairs: {len(val_pos_edges):,} pos, {len(val_neg_edges):,} neg\")\n",
    "assert len(val_pos_edges) == len(val_neg_edges), f\"Mismatch: {len(val_pos_edges)} pos vs {len(val_neg_edges)} neg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "045e0371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing fresh model...\n",
      "============================================================\n",
      "Initializing LightGCN Model\n",
      "============================================================\n",
      "\n",
      "[1/2] Creating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     Building model: 100%|██████████| 1/1 [00:00<00:00, 53.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2/2] Moving to device...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     Moving to cuda: 100%|██████████| 1/1 [00:00<00:00, 84.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Model Initialized\n",
      "============================================================\n",
      "Total time: 0.04s\n",
      "Device: cuda\n",
      "Embedding dimension: 64\n",
      "Number of layers: 3\n",
      "Total parameters: 650,496\n",
      "Trainable parameters: 650,496\n",
      "============================================================\n",
      "\n",
      "✓ Model ready for training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Initialize Fresh Model\n",
    "\n",
    "# Initialize new model for training\n",
    "print(\"Initializing fresh model...\")\n",
    "model = initialize_model_fastest(\n",
    "    num_nodes=num_nodes,\n",
    "    embedding_dim=64,\n",
    "    num_layers=3,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Model ready for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Training with Validation\n",
      "============================================================\n",
      "Device: cuda\n",
      "Epochs: 50\n",
      "Learning rate: 0.001\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  74%|███████▍  | 37/50 [03:25<01:12,  5.56s/epoch, train=0.1981, val=0.1916, best_val=0.1565]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping at epoch 37\n",
      "\n",
      "============================================================\n",
      "Training Complete\n",
      "============================================================\n",
      "Total time: 205.60s (3.43 min)\n",
      "Epochs: 37\n",
      "Best validation loss: 0.1565\n",
      "Final train loss: 0.1981\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Train with Validation\n",
    "\n",
    "def train_with_validation_fastest(model, train_edge_index, train_val_edge_index,\n",
    "                                 train_pos_edges, train_neg_edges,\n",
    "                                 val_pos_edges, val_neg_edges, device,\n",
    "                                 epochs=50, lr=0.001):\n",
    "    \"\"\"\n",
    "    Train model with validation monitoring and early stopping.\n",
    "    \"\"\"\n",
    "    import time\n",
    "    start = time.time()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    patience = 10\n",
    "    no_improve = 0\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"Training with Validation\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Device: {device}\")\n",
    "    print(f\"Epochs: {epochs}\")\n",
    "    print(f\"Learning rate: {lr}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    with tqdm(total=epochs, desc=\"Training\", unit=\"epoch\") as pbar:\n",
    "        for epoch in range(epochs):\n",
    "            # Training\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            embeddings = model(train_edge_index)\n",
    "            \n",
    "            pos_u = embeddings[train_pos_edges[:, 0]]\n",
    "            pos_v = embeddings[train_pos_edges[:, 1]]\n",
    "            pos_scores = (pos_u * pos_v).sum(dim=1)\n",
    "            \n",
    "            neg_u = embeddings[train_neg_edges[:, 0]]\n",
    "            neg_v = embeddings[train_neg_edges[:, 1]]\n",
    "            neg_scores = (neg_u * neg_v).sum(dim=1)\n",
    "            \n",
    "            train_loss = bpr_loss(pos_scores, neg_scores)\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_losses.append(train_loss.item())\n",
    "            \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_embeddings = model(train_val_edge_index)\n",
    "                \n",
    "                val_pos_u = val_embeddings[val_pos_edges[:, 0]]\n",
    "                val_pos_v = val_embeddings[val_pos_edges[:, 1]]\n",
    "                val_pos_scores = (val_pos_u * val_pos_v).sum(dim=1)\n",
    "                \n",
    "                val_neg_u = val_embeddings[val_neg_edges[:, 0]]\n",
    "                val_neg_v = val_embeddings[val_neg_edges[:, 1]]\n",
    "                val_neg_scores = (val_neg_u * val_neg_v).sum(dim=1)\n",
    "                \n",
    "                val_loss = bpr_loss(val_pos_scores, val_neg_scores)\n",
    "                val_losses.append(val_loss.item())\n",
    "            \n",
    "            # Save best model\n",
    "            if val_loss.item() < best_val_loss:\n",
    "                best_val_loss = val_loss.item()\n",
    "                best_model_state = model.state_dict().copy()\n",
    "                no_improve = 0\n",
    "            else:\n",
    "                no_improve += 1\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                'train': f'{train_loss.item():.4f}',\n",
    "                'val': f'{val_loss.item():.4f}',\n",
    "                'best_val': f'{best_val_loss:.4f}'\n",
    "            })\n",
    "            pbar.update(1)\n",
    "            \n",
    "            if no_improve >= patience:\n",
    "                print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(best_model_state)\n",
    "    \n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Training Complete\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Total time: {elapsed:.2f}s ({elapsed/60:.2f} min)\")\n",
    "    print(f\"Epochs: {len(train_losses)}\")\n",
    "    print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "    print(f\"Final train loss: {train_losses[-1]:.4f}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return train_losses, val_losses, model\n",
    "\n",
    "# Train with validation\n",
    "train_losses, val_losses, model = train_with_validation_fastest(\n",
    "    model, train_edge_index, train_val_edge_index,\n",
    "    train_pos_edges, train_neg_edges,\n",
    "    val_pos_edges, val_neg_edges, device,\n",
    "    epochs=50, lr=0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Test Set Evaluation\n",
      "============================================================\n",
      "\n",
      "[1/3] Preparing test edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 108249/108249 [00:05<00:00, 18459.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2/3] Sampling test negative edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 108249/108249 [00:02<00:00, 42178.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3/3] Evaluating...\n",
      "\n",
      "============================================================\n",
      "Test Set Evaluation Results\n",
      "============================================================\n",
      "Test samples: 108,249\n",
      "AUC-ROC: 0.9456\n",
      "Precision: 0.5007\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.6673\n",
      "Evaluation time: 40.60s\n",
      "============================================================\n",
      "\n",
      "✓ Model evaluation complete\n",
      "  - AUC-ROC: 0.9456\n",
      "  - F1 Score: 0.6673\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Final Evaluation on Test Set\n",
    "\n",
    "def evaluate_test_set_fastest(model, train_val_edge_index, test_df, \n",
    "                              fund_to_idx, stock_to_idx, device):\n",
    "    \"\"\"\n",
    "    Evaluate model on test set that was never seen during training.\n",
    "    \"\"\"\n",
    "    import time\n",
    "    start = time.time()\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"Test Set Evaluation\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # Prepare test edges\n",
    "    print(\"\\n[1/3] Preparing test edges...\")\n",
    "    test_pos_pairs = []\n",
    "    for _, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Processing\"):\n",
    "        if row['cik'] in fund_to_idx and row['cusip'] in stock_to_idx:\n",
    "            test_pos_pairs.append([fund_to_idx[row['cik']], stock_to_idx[row['cusip']]])\n",
    "    \n",
    "    test_pos_edges = torch.tensor(test_pos_pairs, dtype=torch.long).to(device)\n",
    "    \n",
    "    # Sample negative edges\n",
    "    print(\"\\n[2/3] Sampling test negative edges...\")\n",
    "    test_neg_edges = []\n",
    "    test_pos_set = set((u.item(), v.item()) for u, v in test_pos_edges)\n",
    "    \n",
    "    for _ in tqdm(range(len(test_pos_edges)), desc=\"Sampling\"):\n",
    "        u = random.randint(0, num_nodes - 1)\n",
    "        v = random.randint(0, num_nodes - 1)\n",
    "        if (u, v) not in test_pos_set and u != v:\n",
    "            test_neg_edges.append([u, v])\n",
    "            if len(test_neg_edges) >= len(test_pos_edges):\n",
    "                break\n",
    "    \n",
    "    test_neg_edges = torch.tensor(test_neg_edges[:len(test_pos_edges)], dtype=torch.long).to(device)\n",
    "    \n",
    "    # Evaluate\n",
    "    print(\"\\n[3/3] Evaluating...\")\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(train_val_edge_index)\n",
    "        \n",
    "        pos_u = embeddings[test_pos_edges[:, 0]]\n",
    "        pos_v = embeddings[test_pos_edges[:, 1]]\n",
    "        pos_scores = (pos_u * pos_v).sum(dim=1).sigmoid()\n",
    "        \n",
    "        neg_u = embeddings[test_neg_edges[:, 0]]\n",
    "        neg_v = embeddings[test_neg_edges[:, 1]]\n",
    "        neg_scores = (neg_u * neg_v).sum(dim=1).sigmoid()\n",
    "        \n",
    "        all_scores = torch.cat([pos_scores, neg_scores]).cpu().numpy()\n",
    "        all_labels = torch.cat([\n",
    "            torch.ones(len(pos_scores)),\n",
    "            torch.zeros(len(neg_scores))\n",
    "        ]).numpy()\n",
    "        \n",
    "        from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n",
    "        \n",
    "        auc = roc_auc_score(all_labels, all_scores)\n",
    "        pred_labels = (all_scores > 0.5).astype(int)\n",
    "        precision = precision_score(all_labels, pred_labels)\n",
    "        recall = recall_score(all_labels, pred_labels)\n",
    "        f1 = f1_score(all_labels, pred_labels)\n",
    "    \n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Test Set Evaluation Results\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Test samples: {len(test_pos_edges):,}\")\n",
    "    print(f\"AUC-ROC: {auc:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Evaluation time: {elapsed:.2f}s\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return {\n",
    "        'auc': auc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'scores': all_scores,\n",
    "        'labels': all_labels\n",
    "    }\n",
    "\n",
    "# Evaluate on test set\n",
    "test_results = evaluate_test_set_fastest(\n",
    "    model, train_val_edge_index, test_df,\n",
    "    fund_to_idx, stock_to_idx, device\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Model evaluation complete\")\n",
    "print(f\"  - AUC-ROC: {test_results['auc']:.4f}\")\n",
    "print(f\"  - F1 Score: {test_results['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Top-K Recommendation Evaluation\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grouping by fund: 100%|██████████| 108249/108249 [00:03<00:00, 32720.23it/s]\n",
      "Evaluating funds: 100%|██████████| 6041/6041 [00:07<00:00, 771.80it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Top-K Results\n",
      "============================================================\n",
      "K= 5: Hit Rate=0.3259, NDCG=0.0964\n",
      "K=10: Hit Rate=0.4999, NDCG=0.1094\n",
      "K=20: Hit Rate=0.6593, NDCG=0.1326\n",
      "K=50: Hit Rate=0.7870, NDCG=0.1777\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Additional Evaluation: Top-K Recommendations\n",
    "# ============================================================================\n",
    "\n",
    "def evaluate_top_k_recommendations_fastest(model, train_val_edge_index, test_df,\n",
    "                                           fund_to_idx, stock_to_idx, device,\n",
    "                                           k_list=[5, 10, 20, 50]):\n",
    "    \"\"\"\n",
    "    Evaluate model using Top-K recommendation metrics (Hit Rate, NDCG).\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Top-K Recommendation Evaluation\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # Group test edges by fund (cik)\n",
    "    fund_to_stocks = {}\n",
    "    for _, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Grouping by fund\"):\n",
    "        if row['cik'] in fund_to_idx and row['cusip'] in stock_to_idx:\n",
    "            fund_idx = fund_to_idx[row['cik']]\n",
    "            stock_idx = stock_to_idx[row['cusip']]\n",
    "            if fund_idx not in fund_to_stocks:\n",
    "                fund_to_stocks[fund_idx] = set()\n",
    "            fund_to_stocks[fund_idx].add(stock_idx)\n",
    "    \n",
    "    # Get embeddings\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(train_val_edge_index)\n",
    "    \n",
    "    results = {k: {'hit_rate': 0, 'ndcg': 0} for k in k_list}\n",
    "    \n",
    "    # For each fund, recommend top K stocks\n",
    "    for fund_idx, true_stocks in tqdm(fund_to_stocks.items(), desc=\"Evaluating funds\"):\n",
    "        fund_emb = embeddings[fund_idx]\n",
    "        \n",
    "        # Calculate scores for all stocks\n",
    "        stock_indices = list(stock_to_idx.values())\n",
    "        stock_embs = embeddings[stock_indices]\n",
    "        scores = (fund_emb * stock_embs).sum(dim=1).cpu().numpy()\n",
    "        \n",
    "        # Get top K recommendations\n",
    "        top_k_indices = np.argsort(scores)[::-1]  # Descending order\n",
    "        \n",
    "        for k in k_list:\n",
    "            top_k_stocks = set([stock_indices[i] for i in top_k_indices[:k]])\n",
    "            \n",
    "            # Hit Rate\n",
    "            hits = len(top_k_stocks & true_stocks)\n",
    "            results[k]['hit_rate'] += 1 if hits > 0 else 0\n",
    "            \n",
    "            # NDCG\n",
    "            if hits > 0:\n",
    "                dcg = 0\n",
    "                for i, stock_idx in enumerate([stock_indices[j] for j in top_k_indices[:k]]):\n",
    "                    if stock_idx in true_stocks:\n",
    "                        dcg += 1 / np.log2(i + 2)\n",
    "                \n",
    "                idcg = sum(1 / np.log2(i + 2) for i in range(min(len(true_stocks), k)))\n",
    "                results[k]['ndcg'] += dcg / idcg if idcg > 0 else 0\n",
    "    \n",
    "    num_funds = len(fund_to_stocks)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Top-K Results\")\n",
    "    print(\"=\" * 60)\n",
    "    for k in k_list:\n",
    "        hit_rate = results[k]['hit_rate'] / num_funds\n",
    "        ndcg = results[k]['ndcg'] / num_funds\n",
    "        print(f\"K={k:2d}: Hit Rate={hit_rate:.4f}, NDCG={ndcg:.4f}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run\n",
    "top_k_results = evaluate_top_k_recommendations_fastest(\n",
    "    model, train_val_edge_index, test_df, fund_to_idx, stock_to_idx, device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6e04079c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Finding Optimal Threshold\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing test edges: 100%|██████████| 108249/108249 [00:02<00:00, 39677.07it/s]\n",
      "Sampling negatives: 100%|██████████| 108249/108249 [00:00<00:00, 535923.72it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimal Threshold: 0.9913\n",
      "Precision: 0.8671\n",
      "Recall: 0.9143\n",
      "F1 Score: 0.8901\n",
      "Average Precision: 0.9299\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Additional Evaluation: Precision-Recall Curve & Optimal Threshold\n",
    "# ============================================================================\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def find_optimal_threshold_fastest(model, train_val_edge_index, test_df,\n",
    "                                   fund_to_idx, stock_to_idx, device):\n",
    "    \"\"\"\n",
    "    Find optimal threshold using Precision-Recall curve.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Finding Optimal Threshold\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # Prepare test edges\n",
    "    test_pos_pairs = []\n",
    "    for _, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Preparing test edges\"):\n",
    "        if row['cik'] in fund_to_idx and row['cusip'] in stock_to_idx:\n",
    "            test_pos_pairs.append([fund_to_idx[row['cik']], stock_to_idx[row['cusip']]])\n",
    "    \n",
    "    test_pos_edges = torch.tensor(test_pos_pairs, dtype=torch.long).to(device)\n",
    "    \n",
    "    # Sample negative edges\n",
    "    test_neg_edges = []\n",
    "    test_pos_set = set((u.item(), v.item()) for u, v in test_pos_edges)\n",
    "    \n",
    "    for _ in tqdm(range(len(test_pos_edges)), desc=\"Sampling negatives\"):\n",
    "        u = random.randint(0, num_nodes - 1)\n",
    "        v = random.randint(0, num_nodes - 1)\n",
    "        if u != v and (u, v) not in test_pos_set:\n",
    "            test_neg_edges.append([u, v])\n",
    "            if len(test_neg_edges) >= len(test_pos_edges):\n",
    "                break\n",
    "    \n",
    "    test_neg_edges = torch.tensor(test_neg_edges[:len(test_pos_edges)], dtype=torch.long).to(device)\n",
    "    \n",
    "    # Get predictions\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(train_val_edge_index)\n",
    "        \n",
    "        pos_u = embeddings[test_pos_edges[:, 0]]\n",
    "        pos_v = embeddings[test_pos_edges[:, 1]]\n",
    "        pos_scores = (pos_u * pos_v).sum(dim=1).sigmoid().cpu().numpy()\n",
    "        \n",
    "        neg_u = embeddings[test_neg_edges[:, 0]]\n",
    "        neg_v = embeddings[test_neg_edges[:, 1]]\n",
    "        neg_scores = (neg_u * neg_v).sum(dim=1).sigmoid().cpu().numpy()\n",
    "        \n",
    "        all_scores = np.concatenate([pos_scores, neg_scores])\n",
    "        all_labels = np.concatenate([np.ones(len(pos_scores)), np.zeros(len(neg_scores))])\n",
    "    \n",
    "    # Calculate Precision-Recall curve\n",
    "    precision, recall, thresholds = precision_recall_curve(all_labels, all_scores)\n",
    "    avg_precision = average_precision_score(all_labels, all_scores)\n",
    "    \n",
    "    # Find optimal threshold (maximize F1)\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
    "    optimal_idx = np.argmax(f1_scores)\n",
    "    optimal_threshold = thresholds[optimal_idx] if optimal_idx < len(thresholds) else 0.5\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(recall, precision, label=f'PR Curve (AP={avg_precision:.4f})')\n",
    "    plt.axvline(x=recall[optimal_idx], color='r', linestyle='--', \n",
    "                label=f'Optimal Threshold={optimal_threshold:.4f}')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    # Evaluate with optimal threshold\n",
    "    pred_labels = (all_scores >= optimal_threshold).astype(int)\n",
    "    from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "    \n",
    "    precision_opt = precision_score(all_labels, pred_labels)\n",
    "    recall_opt = recall_score(all_labels, pred_labels)\n",
    "    f1_opt = f1_score(all_labels, pred_labels)\n",
    "    \n",
    "    print(f\"\\nOptimal Threshold: {optimal_threshold:.4f}\")\n",
    "    print(f\"Precision: {precision_opt:.4f}\")\n",
    "    print(f\"Recall: {recall_opt:.4f}\")\n",
    "    print(f\"F1 Score: {f1_opt:.4f}\")\n",
    "    print(f\"Average Precision: {avg_precision:.4f}\")\n",
    "    \n",
    "    return optimal_threshold, precision, recall, thresholds\n",
    "\n",
    "# Run\n",
    "optimal_threshold, prec, rec, thresh = find_optimal_threshold_fastest(\n",
    "    model, train_val_edge_index, test_df, fund_to_idx, stock_to_idx, device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b981bdba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e2e545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9305d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1dfc19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ed3a4e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Node mappings created\n",
      "  - Funds mapped: 7,058\n",
      "  - Stocks mapped: 2,911\n",
      "  - Total nodes: 9,969\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Prepare Data for LightGCN - Node Mappings\n",
    "\n",
    "def create_node_mappings(funds, stocks):\n",
    "    \"\"\"Create mappings from node IDs to indices for LightGCN.\"\"\"\n",
    "    # Map funds to indices [0, len(funds))\n",
    "    fund_to_idx = {fund: idx for idx, fund in enumerate(funds)}\n",
    "    \n",
    "    # Map stocks to indices [len(funds), len(funds) + len(stocks))\n",
    "    stock_to_idx = {stock: idx + len(funds) for idx, stock in enumerate(stocks)}\n",
    "    \n",
    "    # Combined mapping\n",
    "    node_to_idx = {**fund_to_idx, **stock_to_idx}\n",
    "    \n",
    "    return node_to_idx, fund_to_idx, stock_to_idx\n",
    "\n",
    "# Create mappings (run this before Cell 20)\n",
    "node_to_idx, fund_to_idx, stock_to_idx = create_node_mappings(funds, stocks)\n",
    "\n",
    "print(f\"✓ Node mappings created\")\n",
    "print(f\"  - Funds mapped: {len(fund_to_idx):,}\")\n",
    "print(f\"  - Stocks mapped: {len(stock_to_idx):,}\")\n",
    "print(f\"  - Total nodes: {len(node_to_idx):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4226e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating node mappings...\n",
      "✓ Node mappings created\n",
      "  - Funds: 7,058\n",
      "  - Stocks: 2,911\n",
      "  - Total nodes: 9,969\n",
      "============================================================\n",
      "Converting Graph to PyTorch Geometric Format\n",
      "============================================================\n",
      "\n",
      "[1/4] Extracting edges from graph...\n",
      "     ✓ Extracted 1,082,909 edges in 2.28s\n",
      "\n",
      "[2/4] Processing edge data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     Processing: 100%|██████████| 1.08M/1.08M [00:00<00:00, 2.76Medges/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ✓ Processed in 0.39s\n",
      "\n",
      "[3/4] Mapping nodes to indices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     Mapping: 100%|██████████| 1.08M/1.08M [00:00<00:00, 2.99Medges/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ✓ Mapped in 0.36s\n",
      "\n",
      "[4/4] Creating bidirectional edges and moving to device...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     Creating tensors: 100%|██████████| 1/1 [00:00<00:00, 12.22it/s]\n",
      "     Moving to device: 100%|██████████| 2/2 [00:00<00:00,  7.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     ✓ Completed in 0.36s\n",
      "\n",
      "============================================================\n",
      "Conversion Complete\n",
      "============================================================\n",
      "Total time: 3.40s\n",
      "Speed: 318,107 edges/second\n",
      "Edge index shape: torch.Size([2, 2165818]) (on cuda)\n",
      "Edge weights shape: torch.Size([2165818]) (on cuda)\n",
      "Total bidirectional edges: 2,165,818\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Prepare Data for LightGCN (Fastest with Progress Tracking)\n",
    "\n",
    "def create_node_mappings(funds, stocks):\n",
    "    \"\"\"Create mappings from node IDs to indices for LightGCN.\"\"\"\n",
    "    fund_to_idx = {fund: idx for idx, fund in enumerate(funds)}\n",
    "    stock_to_idx = {stock: idx + len(funds) for idx, stock in enumerate(stocks)}\n",
    "    node_to_idx = {**fund_to_idx, **stock_to_idx}\n",
    "    \n",
    "    return node_to_idx, fund_to_idx, stock_to_idx\n",
    "\n",
    "def graph_to_edge_index_fastest(G, node_to_idx, device):\n",
    "    \"\"\"\n",
    "    Fastest conversion using vectorized operations with progress tracking.\n",
    "    All tensors are created on CPU then moved to device (faster).\n",
    "    \"\"\"\n",
    "    import time\n",
    "    start = time.time()\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"Converting Graph to PyTorch Geometric Format\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Get all edges\n",
    "    print(\"\\n[1/4] Extracting edges from graph...\")\n",
    "    extract_start = time.time()\n",
    "    edges_data = list(G.edges(data=True))\n",
    "    num_edges = len(edges_data)\n",
    "    print(f\"     ✓ Extracted {num_edges:,} edges in {time.time() - extract_start:.2f}s\")\n",
    "    \n",
    "    # Extract u, v, weights (vectorized)\n",
    "    print(\"\\n[2/4] Processing edge data...\")\n",
    "    process_start = time.time()\n",
    "    \n",
    "    with tqdm(total=num_edges, desc=\"     Processing\", unit=\"edges\", unit_scale=True) as pbar:\n",
    "        u_nodes = [u for u, _, _ in edges_data]\n",
    "        v_nodes = [v for _, v, _ in edges_data]\n",
    "        weights_list = [data.get('weight', 1.0) for _, _, data in edges_data]\n",
    "        pbar.update(num_edges)\n",
    "    \n",
    "    print(f\"     ✓ Processed in {time.time() - process_start:.2f}s\")\n",
    "    \n",
    "    # Map to indices (vectorized)\n",
    "    print(\"\\n[3/4] Mapping nodes to indices...\")\n",
    "    map_start = time.time()\n",
    "    \n",
    "    with tqdm(total=num_edges, desc=\"     Mapping\", unit=\"edges\", unit_scale=True) as pbar:\n",
    "        u_indices = torch.tensor([node_to_idx[u] for u in u_nodes], dtype=torch.long)\n",
    "        v_indices = torch.tensor([node_to_idx[v] for v in v_nodes], dtype=torch.long)\n",
    "        weights = torch.tensor(weights_list, dtype=torch.float)\n",
    "        pbar.update(num_edges)\n",
    "    \n",
    "    print(f\"     ✓ Mapped in {time.time() - map_start:.2f}s\")\n",
    "    \n",
    "    # Create bidirectional edges (vectorized)\n",
    "    print(\"\\n[4/4] Creating bidirectional edges and moving to device...\")\n",
    "    create_start = time.time()\n",
    "    \n",
    "    with tqdm(total=1, desc=\"     Creating tensors\") as pbar:\n",
    "        # Concatenate for bidirectional\n",
    "        u_bidirectional = torch.cat([u_indices, v_indices])\n",
    "        v_bidirectional = torch.cat([v_indices, u_indices])\n",
    "        weights_bidirectional = torch.cat([weights, weights])\n",
    "        \n",
    "        # Create edge_index\n",
    "        edge_index = torch.stack([u_bidirectional, v_bidirectional]).contiguous()\n",
    "        pbar.update(1)\n",
    "    \n",
    "    # Move to device\n",
    "    with tqdm(total=2, desc=\"     Moving to device\") as pbar:\n",
    "        edge_index = edge_index.to(device)\n",
    "        pbar.update(1)\n",
    "        edge_weights = weights_bidirectional.to(device)\n",
    "        pbar.update(1)\n",
    "    \n",
    "    elapsed = time.time() - start\n",
    "    print(f\"\\n     ✓ Completed in {time.time() - create_start:.2f}s\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Conversion Complete\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Total time: {elapsed:.2f}s\")\n",
    "    print(f\"Speed: {num_edges/elapsed:,.0f} edges/second\")\n",
    "    print(f\"Edge index shape: {edge_index.shape} (on {device})\")\n",
    "    print(f\"Edge weights shape: {edge_weights.shape} (on {device})\")\n",
    "    print(f\"Total bidirectional edges: {edge_index.shape[1]:,}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return edge_index, edge_weights\n",
    "\n",
    "# Create mappings\n",
    "print(\"Creating node mappings...\")\n",
    "node_to_idx, fund_to_idx, stock_to_idx = create_node_mappings(funds, stocks)\n",
    "\n",
    "print(f\"✓ Node mappings created\")\n",
    "print(f\"  - Funds: {len(fund_to_idx):,}\")\n",
    "print(f\"  - Stocks: {len(stock_to_idx):,}\")\n",
    "print(f\"  - Total nodes: {len(node_to_idx):,}\")\n",
    "\n",
    "# Convert to PyTorch Geometric format (fastest, on device)\n",
    "edge_index, edge_weights = graph_to_edge_index_fastest(G_bipartite, node_to_idx, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f479ec77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Creating PyTorch Geometric Data Object\n",
      "============================================================\n",
      "\n",
      "[1/2] Creating node features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     Generating features: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ✓ Created in 0.14s\n",
      "     Feature shape: torch.Size([9969, 64])\n",
      "\n",
      "[2/2] Creating Data object...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     Assembling data: 100%|██████████| 1/1 [00:00<00:00, 7825.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ✓ Created in 0.00s\n",
      "\n",
      "============================================================\n",
      "Data Object Created\n",
      "============================================================\n",
      "Total time: 0.14s\n",
      "Device: cuda\n",
      "Node features shape: torch.Size([9969, 64])\n",
      "Edge index shape: torch.Size([2, 2165818])\n",
      "Edge attributes shape: torch.Size([2165818])\n",
      "Total nodes: 9,969\n",
      "============================================================\n",
      "\n",
      "✓ PyG Data object ready for training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Create PyTorch Geometric Data Object (Fastest with Progress)\n",
    "\n",
    "def create_pyg_data_fastest(edge_index, edge_weights, num_nodes, device, node_features=None):\n",
    "    \"\"\"\n",
    "    Create PyTorch Geometric Data object on specified device.\n",
    "    Fastest method with progress tracking.\n",
    "    \"\"\"\n",
    "    import time\n",
    "    start = time.time()\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"Creating PyTorch Geometric Data Object\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create node features\n",
    "    print(\"\\n[1/2] Creating node features...\")\n",
    "    feature_start = time.time()\n",
    "    \n",
    "    if node_features is None:\n",
    "        # Create random features directly on device (faster)\n",
    "        with tqdm(total=1, desc=\"     Generating features\") as pbar:\n",
    "            node_features = torch.randn(num_nodes, 64, device=device)\n",
    "            pbar.update(1)\n",
    "    else:\n",
    "        # Move existing features to device\n",
    "        with tqdm(total=1, desc=\"     Moving features to device\") as pbar:\n",
    "            node_features = node_features.to(device)\n",
    "            pbar.update(1)\n",
    "    \n",
    "    print(f\"     ✓ Created in {time.time() - feature_start:.2f}s\")\n",
    "    print(f\"     Feature shape: {node_features.shape}\")\n",
    "    \n",
    "    # Create Data object\n",
    "    print(\"\\n[2/2] Creating Data object...\")\n",
    "    data_start = time.time()\n",
    "    \n",
    "    with tqdm(total=1, desc=\"     Assembling data\") as pbar:\n",
    "        data = Data(\n",
    "            x=node_features,\n",
    "            edge_index=edge_index,  # Already on device\n",
    "            edge_attr=edge_weights  # Already on device\n",
    "        )\n",
    "        pbar.update(1)\n",
    "    \n",
    "    elapsed = time.time() - start\n",
    "    print(f\"     ✓ Created in {time.time() - data_start:.2f}s\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Data Object Created\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Total time: {elapsed:.2f}s\")\n",
    "    print(f\"Device: {device}\")\n",
    "    print(f\"Node features shape: {data.x.shape}\")\n",
    "    print(f\"Edge index shape: {data.edge_index.shape}\")\n",
    "    print(f\"Edge attributes shape: {data.edge_attr.shape}\")\n",
    "    print(f\"Total nodes: {num_nodes:,}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Create data object (fastest, on device)\n",
    "num_nodes = len(funds) + len(stocks)\n",
    "data = create_pyg_data_fastest(edge_index, edge_weights, num_nodes, device)\n",
    "\n",
    "print(f\"\\n✓ PyG Data object ready for training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6b148c",
   "metadata": {},
   "source": [
    "## Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9775de14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Initializing LightGCN Model\n",
      "============================================================\n",
      "\n",
      "[1/2] Creating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     Building model: 100%|██████████| 1/1 [00:00<00:00, 10.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2/2] Moving to device...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     Moving to cuda: 100%|██████████| 1/1 [00:00<00:00, 33.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Model Initialized\n",
      "============================================================\n",
      "Total time: 0.13s\n",
      "Device: cuda\n",
      "Embedding dimension: 64\n",
      "Number of layers: 3\n",
      "Total parameters: 650,496\n",
      "Trainable parameters: 650,496\n",
      "============================================================\n",
      "\n",
      "✓ LightGCN model ready for training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 4: LightGCN Model Definition (Fastest with Progress)\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class LightGCN(nn.Module):\n",
    "    \"\"\"\n",
    "    LightGCN model for bipartite graph recommendation.\n",
    "    Simplified version without feature transformation.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_nodes, embedding_dim=64, num_layers=3):\n",
    "        super(LightGCN, self).__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(num_nodes, embedding_dim)\n",
    "        nn.init.normal_(self.embedding.weight, std=0.1)\n",
    "        \n",
    "        # GCN layers\n",
    "        self.convs = nn.ModuleList([\n",
    "            GCNConv(embedding_dim, embedding_dim, improved=False, cached=False)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "    \n",
    "    def forward(self, edge_index):\n",
    "        \"\"\"Forward pass through LightGCN layers.\"\"\"\n",
    "        x = self.embedding.weight\n",
    "        \n",
    "        # Aggregate embeddings from all layers\n",
    "        embeddings = [x]\n",
    "        \n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index)\n",
    "            embeddings.append(x)\n",
    "        \n",
    "        # Average all layer embeddings (LightGCN approach)\n",
    "        final_embedding = torch.stack(embeddings, dim=0).mean(dim=0)\n",
    "        \n",
    "        return final_embedding\n",
    "\n",
    "def initialize_model_fastest(num_nodes, embedding_dim, num_layers, device):\n",
    "    \"\"\"\n",
    "    Initialize LightGCN model and move to device with progress tracking.\n",
    "    \"\"\"\n",
    "    import time\n",
    "    start = time.time()\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"Initializing LightGCN Model\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(\"\\n[1/2] Creating model...\")\n",
    "    with tqdm(total=1, desc=\"     Building model\") as pbar:\n",
    "        model = LightGCN(num_nodes=num_nodes, embedding_dim=embedding_dim, num_layers=num_layers)\n",
    "        pbar.update(1)\n",
    "    \n",
    "    print(\"\\n[2/2] Moving to device...\")\n",
    "    with tqdm(total=1, desc=f\"     Moving to {device}\") as pbar:\n",
    "        model = model.to(device)\n",
    "        pbar.update(1)\n",
    "    \n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Model Initialized\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Total time: {elapsed:.2f}s\")\n",
    "    print(f\"Device: {device}\")\n",
    "    print(f\"Embedding dimension: {embedding_dim}\")\n",
    "    print(f\"Number of layers: {num_layers}\")\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Initialize model (fastest, on device)\n",
    "model = initialize_model_fastest(\n",
    "    num_nodes=num_nodes,\n",
    "    embedding_dim=64,\n",
    "    num_layers=3,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ LightGCN model ready for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24382a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Creating Training Pairs\n",
      "============================================================\n",
      "\n",
      "[1/3] Extracting positive edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     Extracting: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ✓ Extracted 2,165,818 positive edges in 0.82s\n",
      "\n",
      "[2/3] Creating positive edge set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     Building set: 100%|██████████| 1/1 [00:02<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ✓ Created set in 2.05s\n",
      "\n",
      "[3/3] Sampling 1x negative edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     Sampling negatives: 2.20Medges [00:04, 486kedges/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ✓ Sampled 2,165,818 negative edges in 4.53s\n",
      "\n",
      "[4/4] Creating tensors and moving to device...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     Creating tensors: 100%|██████████| 2/2 [00:00<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ✓ Completed in 0.69s\n",
      "\n",
      "============================================================\n",
      "Training Pairs Created\n",
      "============================================================\n",
      "Total time: 8.09s\n",
      "Positive edges: 2,165,818\n",
      "Negative edges: 2,165,818\n",
      "Ratio: 1.00x\n",
      "Device: cuda\n",
      "============================================================\n",
      "\n",
      "✓ Training pairs ready on cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 5: Training Setup (Fastest with Progress Tracking)\n",
    "\n",
    "def create_positive_negative_pairs_fastest(edge_index, num_nodes, device, num_negatives=1):\n",
    "    \"\"\"\n",
    "    Create positive and negative edge pairs for training.\n",
    "    Optimized with progress tracking and efficient sampling.\n",
    "    \"\"\"\n",
    "    import time\n",
    "    start = time.time()\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"Creating Training Pairs\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Extract positive edges\n",
    "    print(\"\\n[1/3] Extracting positive edges...\")\n",
    "    pos_start = time.time()\n",
    "    \n",
    "    with tqdm(total=1, desc=\"     Extracting\") as pbar:\n",
    "        pos_edges = edge_index.t().tolist()\n",
    "        pbar.update(1)\n",
    "    \n",
    "    pos_count = len(pos_edges)\n",
    "    print(f\"     ✓ Extracted {pos_count:,} positive edges in {time.time() - pos_start:.2f}s\")\n",
    "    \n",
    "    # Create positive set for fast lookup\n",
    "    print(\"\\n[2/3] Creating positive edge set...\")\n",
    "    set_start = time.time()\n",
    "    \n",
    "    with tqdm(total=1, desc=\"     Building set\") as pbar:\n",
    "        pos_set = set((u, v) for u, v in pos_edges)\n",
    "        pbar.update(1)\n",
    "    \n",
    "    print(f\"     ✓ Created set in {time.time() - set_start:.2f}s\")\n",
    "    \n",
    "    # Sample negative edges\n",
    "    print(f\"\\n[3/3] Sampling {num_negatives}x negative edges...\")\n",
    "    neg_start = time.time()\n",
    "    \n",
    "    target_neg_count = pos_count * num_negatives\n",
    "    neg_edges = []\n",
    "    \n",
    "    # Use numpy for faster random sampling\n",
    "    with tqdm(total=target_neg_count, desc=\"     Sampling negatives\", unit=\"edges\", unit_scale=True) as pbar:\n",
    "        attempts = 0\n",
    "        max_attempts = target_neg_count * 10  # Safety limit\n",
    "        \n",
    "        while len(neg_edges) < target_neg_count and attempts < max_attempts:\n",
    "            # Batch sampling for efficiency\n",
    "            batch_size = min(10000, target_neg_count - len(neg_edges))\n",
    "            u_batch = np.random.randint(0, num_nodes, size=batch_size)\n",
    "            v_batch = np.random.randint(0, num_nodes, size=batch_size)\n",
    "            \n",
    "            for u, v in zip(u_batch, v_batch):\n",
    "                if (u, v) not in pos_set and u != v:\n",
    "                    neg_edges.append([int(u), int(v)])\n",
    "                    if len(neg_edges) >= target_neg_count:\n",
    "                        break\n",
    "            \n",
    "            attempts += batch_size\n",
    "            pbar.update(min(batch_size, target_neg_count - len(neg_edges)))\n",
    "    \n",
    "    neg_count = len(neg_edges)\n",
    "    print(f\"     ✓ Sampled {neg_count:,} negative edges in {time.time() - neg_start:.2f}s\")\n",
    "    \n",
    "    # Convert to tensors and move to device\n",
    "    print(\"\\n[4/4] Creating tensors and moving to device...\")\n",
    "    tensor_start = time.time()\n",
    "    \n",
    "    with tqdm(total=2, desc=\"     Creating tensors\") as pbar:\n",
    "        pos_tensor = torch.tensor(pos_edges, dtype=torch.long).to(device)\n",
    "        pbar.update(1)\n",
    "        neg_tensor = torch.tensor(neg_edges, dtype=torch.long).to(device)\n",
    "        pbar.update(1)\n",
    "    \n",
    "    elapsed = time.time() - start\n",
    "    print(f\"     ✓ Completed in {time.time() - tensor_start:.2f}s\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Training Pairs Created\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Total time: {elapsed:.2f}s\")\n",
    "    print(f\"Positive edges: {pos_count:,}\")\n",
    "    print(f\"Negative edges: {neg_count:,}\")\n",
    "    print(f\"Ratio: {neg_count/pos_count:.2f}x\")\n",
    "    print(f\"Device: {device}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return pos_tensor, neg_tensor\n",
    "\n",
    "# Create training pairs (fastest, on device)\n",
    "pos_edges, neg_edges = create_positive_negative_pairs_fastest(edge_index, num_nodes, device, num_negatives=1)\n",
    "\n",
    "print(f\"\\n✓ Training pairs ready on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffbf36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training on cuda...\n",
      "============================================================\n",
      "Training LightGCN\n",
      "============================================================\n",
      "Device: cuda\n",
      "Epochs: 50\n",
      "Learning rate: 0.001\n",
      "Positive edges: 2,165,818\n",
      "Negative edges: 2,165,818\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|████████  | 40/50 [00:19<00:04,  2.07epoch/s, loss=0.1858, best=0.1517, time=0.29s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping at epoch 40 (no improvement for 10 epochs)\n",
      "\n",
      "============================================================\n",
      "Training Complete\n",
      "============================================================\n",
      "Total time: 19.33s (0.32 min)\n",
      "Epochs completed: 40\n",
      "Final loss: 0.1858\n",
      "Best loss: 0.1517\n",
      "Average time per epoch: 0.48s\n",
      "============================================================\n",
      "\n",
      "✓ Training completed\n",
      "  - Final loss: 0.1858\n",
      "  - Embeddings shape: torch.Size([9969, 64]) (on cuda)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Training Loop (Fastest with Progress Tracking)\n",
    "\n",
    "def bpr_loss(pos_scores, neg_scores):\n",
    "    \"\"\"Bayesian Personalized Ranking loss.\"\"\"\n",
    "    return -torch.log(torch.sigmoid(pos_scores - neg_scores) + 1e-10).mean()\n",
    "\n",
    "def train_lightgcn_fastest(model, edge_index, pos_edges, neg_edges, device, epochs=50, lr=0.001):\n",
    "    \"\"\"\n",
    "    Train LightGCN model using BPR loss on specified device.\n",
    "    Optimized with progress tracking and early stopping.\n",
    "    \"\"\"\n",
    "    import time\n",
    "    start = time.time()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    model.train()\n",
    "    \n",
    "    losses = []\n",
    "    best_loss = float('inf')\n",
    "    patience = 10\n",
    "    no_improve = 0\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"Training LightGCN\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Device: {device}\")\n",
    "    print(f\"Epochs: {epochs}\")\n",
    "    print(f\"Learning rate: {lr}\")\n",
    "    print(f\"Positive edges: {len(pos_edges):,}\")\n",
    "    print(f\"Negative edges: {len(neg_edges):,}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Training loop with progress bar\n",
    "    with tqdm(total=epochs, desc=\"Training\", unit=\"epoch\") as pbar:\n",
    "        for epoch in range(epochs):\n",
    "            epoch_start = time.time()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            embeddings = model(edge_index)\n",
    "            \n",
    "            # Positive scores\n",
    "            pos_u = embeddings[pos_edges[:, 0]]\n",
    "            pos_v = embeddings[pos_edges[:, 1]]\n",
    "            pos_scores = (pos_u * pos_v).sum(dim=1)\n",
    "            \n",
    "            # Negative scores\n",
    "            neg_u = embeddings[neg_edges[:, 0]]\n",
    "            neg_v = embeddings[neg_edges[:, 1]]\n",
    "            neg_scores = (neg_u * neg_v).sum(dim=1)\n",
    "            \n",
    "            # Loss\n",
    "            loss = bpr_loss(pos_scores, neg_scores)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_val = loss.item()\n",
    "            losses.append(loss_val)\n",
    "            \n",
    "            # Early stopping check\n",
    "            if loss_val < best_loss:\n",
    "                best_loss = loss_val\n",
    "                no_improve = 0\n",
    "            else:\n",
    "                no_improve += 1\n",
    "            \n",
    "            epoch_time = time.time() - epoch_start\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{loss_val:.4f}',\n",
    "                'best': f'{best_loss:.4f}',\n",
    "                'time': f'{epoch_time:.2f}s'\n",
    "            })\n",
    "            pbar.update(1)\n",
    "            \n",
    "            # Early stopping\n",
    "            if no_improve >= patience:\n",
    "                print(f\"\\nEarly stopping at epoch {epoch+1} (no improvement for {patience} epochs)\")\n",
    "                break\n",
    "    \n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Training Complete\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Total time: {elapsed:.2f}s ({elapsed/60:.2f} min)\")\n",
    "    print(f\"Epochs completed: {len(losses)}\")\n",
    "    print(f\"Final loss: {losses[-1]:.4f}\")\n",
    "    print(f\"Best loss: {best_loss:.4f}\")\n",
    "    print(f\"Average time per epoch: {elapsed/len(losses):.2f}s\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return losses, embeddings\n",
    "\n",
    "# Train model (fastest, on device)\n",
    "print(f\"Starting training on {device}...\")\n",
    "losses, final_embeddings = train_lightgcn_fastest(\n",
    "    model, edge_index, pos_edges, neg_edges, device, \n",
    "    epochs=50, lr=0.001\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Training completed\")\n",
    "print(f\"  - Final loss: {losses[-1]:.4f}\")\n",
    "print(f\"  - Embeddings shape: {final_embeddings.shape} (on {device})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
